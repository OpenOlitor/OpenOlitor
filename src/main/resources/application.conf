spray.can {
  server {
    # The value of the `Server` header to produce.
    # Set to the empty string to disable rendering of the server header.
    server-header = spray-can/${spray.version}

    # The maximum number of requests that are accepted (and dispatched to
    # the application) on one single connection before the first request
    # has to be completed.
    # Incoming requests that would cause the pipelining limit to be exceeded
    # are not read from the connections socket so as to build up "back-pressure"
    # to the client via TCP flow control.
    # A setting of 1 disables HTTP pipelining, since only one request per
    # connection can be "open" (i.e. being processed by the application) at any
    # time. Set to higher values to enable HTTP pipelining.
    # Set to 'disabled' for completely disabling pipelining limits
    # (not recommended on public-facing servers due to risk of DoS attacks).
    # This value must be > 0 and <= 128.
    pipelining-limit = 1

    # The time after which an idle connection will be automatically closed.
    # Set to `infinite` to completely disable idle connection timeouts.
    idle-timeout = 650 s

    # If a request hasn't been responded to after the time period set here
    # a `spray.http.Timedout` message will be sent to the timeout handler.
    # Set to `infinite` to completely disable request timeouts.
    request-timeout = 600 s

    # After a `Timedout` message has been sent to the timeout handler and the
    # request still hasn't been completed after the time period set here
    # the server will complete the request itself with an error response.
    # Set to `infinite` to disable timeout timeouts.
    timeout-timeout = 10 s

    # The period during which a service must respond to a `ChunkedRequestStart` message
    # with a `RegisterChunkHandler` message. During the registration period reading from
    # the network is suspended. It is still possible that some chunks have already been
    # received which will be buffered until the registration is received or the timeout is
    # triggered. If the timeout is triggered the connection is immediately aborted.
    chunkhandler-registration-timeout = 500 ms

    # The path of the actor to send `spray.http.Timedout` messages to.
    # If empty all `Timedout` messages will go to the "regular" request
    # handling actor.
    timeout-handler = ""

    # The "granularity" of timeout checking for both idle connections timeouts
    # as well as request timeouts, should rarely be needed to modify.
    # If set to `infinite` request and connection timeout checking is disabled.
    reaping-cycle = 250 ms

    # Enables/disables support for statistics collection and querying.
    # Even though stats keeping overhead is small,
    # for maximum performance switch off when not needed.
    stats-support = on

    # Enables/disables the addition of a `Remote-Address` header
    # holding the clients (remote) IP address.
    remote-address-header = off

    # Enables/disables the addition of a `Raw-Request-URI` header holding the
    # original raw request URI as the client has sent it.
    raw-request-uri-header = off

    # Enables/disables automatic handling of HEAD requests.
    # If this setting is enabled the server dispatches HEAD requests as GET
    # requests to the application and automatically strips off all message
    # bodies from outgoing responses.
    # Note that, even when this setting is off the server will never send
    # out message bodies on responses to HEAD requests.
    transparent-head-requests = on

    # Enables/disables an alternative response streaming mode that doesn't
    # use `Transfer-Encoding: chunked` but rather renders the individual
    # MessageChunks coming in from the application as parts of the original
    # response entity.
    # Enabling this mode causes all connections to be closed after a streaming
    # response has been finished since there is no other way to signal the
    # response end to the client.
    # Note that chunkless-streaming is implicitly enabled when streaming
    # responses to HTTP/1.0 clients (since they don't support
    # `Transfer-Encoding: chunked`)
    chunkless-streaming = on	
	
    # Enables/disables the returning of more detailed error messages to
    # the client in the error response.
    # Should be disabled for browser-facing APIs due to the risk of XSS attacks
    # and (probably) enabled for internal or non-browser APIs.
    # Note that spray will always produce log messages containing the full
    # error details.
    verbose-error-messages = off

    # If this setting is non-zero the HTTP server automatically aggregates
    # incoming request chunks into full HttpRequests before dispatching them to
    # the application. If the size of the aggregated requests surpasses the
    # specified limit the server responds with a `413 Request Entity Too Large`
    # error response before closing the connection.
    # Set to zero to disable automatic request chunk aggregation and have
    # ChunkedRequestStart, MessageChunk and ChunkedMessageEnd messages be
    # dispatched to the handler.
    request-chunk-aggregation-limit = 1m

    # The initial size if the buffer to render the response headers in.
    # Can be used for fine-tuning response rendering performance but probably
    # doesn't have to be fiddled with in most applications.
    response-header-size-hint = 512

    # For HTTPS connections this setting specified the maximum number of
    # bytes that are encrypted in one go. Large responses are broken down in
    # chunks of this size so as to already begin sending before the response has
    # been encrypted entirely.
    max-encryption-chunk-size = 1m

    # The time period within which the TCP binding process must be completed.
    # Set to `infinite` to disable.
    bind-timeout = 10s

    # The time period within which the TCP unbinding process must be completed.
    # Set to `infinite` to disable.
    unbind-timeout = 10s

    # The time period within which a connection handler must have been
    # registered after the bind handler has received a `Connected` event.
    # Set to `infinite` to disable.
    registration-timeout = 10s

    # The time after which a connection is aborted (RST) after a parsing error
    # occurred. The timeout prevents a connection which is already known to be
    # erroneous from receiving evermore data even if all of the data will be ignored.
    # However, in case of a connection abortion the client usually doesn't properly
    # receive the error response. This timeout is a trade-off which allows the client
    # some time to finish its request and receive a proper error response before the
    # connection is forcibly closed to free resources.
    parsing-error-abort-timeout = 2s

    # If this setting is empty the server only accepts requests that carry a
    # non-empty `Host` header. Otherwise it responds with `400 Bad Request`.
    # Set to a non-empty value to be used in lieu of a missing or empty `Host`
    # header to make the server accept such requests.
    # Note that the server will never accept HTTP/1.1 request without a `Host`
    # header, i.e. this setting only affects HTTP/1.1 requests with an empty
    # `Host` header as well as HTTP/1.0 requests.
    # Examples: `www.spray.io` or `example.com:8080`
    default-host-header = "openolitor"

    # Enables/disables automatic back-pressure handling by write buffering and
    # receive throttling
    automatic-back-pressure-handling = on

    back-pressure {
        # The reciprocal rate of requested Acks per NoAcks. E.g. the default value
        # '10' means that every 10th write request is acknowledged. This affects the
        # number of writes each connection has to buffer even in absence of back-pressure.
        noack-rate = 10

        # The lower limit the write queue size has to shrink to before reads are resumed.
        # Use 'infinite' to disable the low-watermark so that reading is resumed instantly
        # after the next successful write.
        reading-low-watermark = infinite
    }

    # Enables more verbose DEBUG logging for debugging SSL related issues.
    ssl-tracing = off

    # Modify to tweak parsing settings on the server-side only.
    parsing = ${spray.can.parsing}
  }

  client {
    # The default value of the `User-Agent` header to produce if no
    # explicit `User-Agent`-header was included in a request.
    # If this value is the empty string and no header was included in
    # the request, no `User-Agent` header will be rendered at all.
    user-agent-header = spray-can/${spray.version}

    # The time after which an idle connection will be automatically closed.
    # Set to `infinite` to completely disable idle timeouts.
    idle-timeout = 650s

    # The max time period that a client connection will be waiting for a response
    # before triggering a request timeout. The timer for this logic is not started
    # until the connection is actually in a state to receive the response, which
    # may be quite some time after the request has been received from the
    # application!
    # There are two main reasons to delay the start of the request timeout timer:
    # 1. On the host-level API with pipelining disabled:
    #    If the request cannot be sent immediately because all connections are
    #    currently busy with earlier requests it has to be queued until a
    #    connection becomes available.
    # 2. With pipelining enabled:
    #    The request timeout timer starts only once the response for the
    #    preceding request on the connection has arrived.
    # Set to `infinite` to completely disable request timeouts.
    request-timeout = 600s

    # the "granularity" of timeout checking for both idle connections timeouts
    # as well as request timeouts, should rarely be needed to modify.
    # If set to `infinite` request and connection timeout checking is disabled.
    reaping-cycle = 250 ms

    # If this setting is non-zero the HTTP client connections automatically
    # aggregate incoming response chunks into full HttpResponses before
    # dispatching them to the application.
    # If the size of the aggregated response surpasses the specified limit the
    # HTTP client connection is closed and an error returned.
    # Set to zero to disable automatic request chunk aggregation and have
    # ChunkedResponseStart, MessageChunk and ChunkedMessageEnd messages be
    # dispatched to the application.
    response-chunk-aggregation-limit = 1m

    # Enables/disables an alternative request streaming mode that doesn't
    # use `Transfer-Encoding: chunked` but rather renders the individual
    # MessageChunks coming in from the application as parts of the original
    # request entity.
    # Enabling this mode causes all requests to require an explicit `Content-Length`
    # header for streaming requests.
    # Note that chunkless-streaming is implicitly enabled when streaming
    # HTTP/1.0 requests since they don't support `Transfer-Encoding: chunked`.
    chunkless-streaming = off

    # The initial size if the buffer to render the request headers in.
    # Can be used for fine-tuning request rendering performance but probably
    # doesn't have to be fiddled with in most applications.
    request-header-size-hint = 512

    # For HTTPS connections this setting specified the maximum number of
    # bytes that are encrypted in one go. Large requests are broken down in
    # chunks of this size so as to already begin sending before the request has
    # been encrypted entirely.
    max-encryption-chunk-size = 1m

    # The time period within which the TCP connecting process must be completed.
    # Set to `infinite` to disable.
    connecting-timeout = 10s

    # Modify to tweak parsing settings on the client-side only.
    parsing = ${spray.can.parsing}
  }
  parsing {
    # The limits for the various parts of the HTTP message parser.
    max-uri-length             = 2k
    max-response-reason-length = 64
    max-header-name-length     = 64
    max-header-value-length    = 8k
    max-header-count           = 64
    max-content-length         = 20m
    max-chunk-ext-length       = 256
    max-chunk-size             = 1m
  }
}


openolitor {
	run-proxy-service: true,
	port: 9003,
	mandanten: ["m1", "m2"],	
	m1: {
		name: "mandant1",		
		port: 9004,
		webservicePort: 10004,
		
		# Project specific akka persistence configuration
		akka-persistence-sql-async {
		  url = "jdbc:mysql://localhost:3307/m1"
		  user = "super"
		  password = "openolitor"
		}
		
		# Mandant specific db settings
		db: {
			default: {
				url="jdbc:mysql://localhost:3307/m1"				
				user="super"
				password="openolitor"
			}
		}
		
		# Buchhaltung
		buchhaltung: {
		  # Der Prefix hat zusammen mit der Rechnungsnummer (200000) und der Kundennummer(30000) eine maximale Länge von 26 Zeichen
		  referenznummer-prefix=""
		  # Die Rechnungsnummer & Kundennummer in der Referenznummer werden mit Nullen bis zu diesen Längen von vorne aufgefüllt
		  rechnung-id-length=6
		  kunde-id-length=5
		  # Teilnehmernummer ohne Sonderzeichen [0-9]{9}
		  teilnehmernummer="777777777"
		}
    
    s3 {
      aws-endpoint="http://localhost:4569"
      aws-access-key-id="your_key"
      aws-secret-acccess-key="your_secret"
    }
    
    smtp {
      from="info@openolitor.ch"
      endpoint="localhost"
      port=25
      user="info@openolitor.ch"
      password="super"
      number-of-retries=5
      send-email=false
    }
    
    converttopdf {
      endpoint="http://pdftools.openolitor.ch/convert2pdf"
    }
	},
	m2: {
		name: "mandant2",		
		
		# Mandant specific akka persistence configuration
		akka-persistence-sql-async {
		  url = "jdbc:mysql://localhost:3307/m2"
          user="super"
          password="openolitor"
		},
		
		# Mandant specific db settings
		db: {
			default: {
				url="jdbc:mysql://localhost:3307/m2"
                user="super"
                password="openolitor"
			}
		}
		
		# Buchhaltung
    buchhaltung: {
      # Der Prefix hat zusammen mit der Rechnungsnummer (200000) und der Kundennummer(30000) eine maximale Länge von 26 Zeichen
      referenznummer-prefix=""
      # Die Rechnungsnummer & Kundennummer in der Referenznummer werden mit Nullen bis zu diesen Längen von vorne aufgefüllt
      rechnung-id-length=6
      kunde-id-length=5
      # Teilnehmernummer ohne Sonderzeichen [0-9]{9}
      teilnehmernummer="777777777"
    }
		
		s3 {
      aws-endpoint="http://localhost:4569"
      aws-access-key-id="your_key"
      aws-secret-acccess-key="your_secret"
    }
    
    smtp {
      from="info@openolitor.ch"
      endpoint="localhost"
      port=25
      user="info@openolitor.ch"
      password="super"
      number-of-retries=5
      send-email=false
    }
    
    converttopdf {
      endpoitn="http://pdftools.openolitor.ch/convert2pdf"
    }
	},
	
	# DB Seed configuration
	db.default.seed {
		models = [
			ch.openolitor.core.models.PersonId,
			ch.openolitor.stammdaten.models.ProjektId,
			ch.openolitor.stammdaten.models.DepotId,
			ch.openolitor.stammdaten.models.TourId,
			ch.openolitor.stammdaten.models.KundeId,		
			ch.openolitor.stammdaten.models.AbotypId,
			ch.openolitor.stammdaten.models.AboId,
			ch.openolitor.stammdaten.models.ProduktId,
			ch.openolitor.stammdaten.models.ProduzentId,
			ch.openolitor.stammdaten.models.VertriebId,
			ch.openolitor.buchhaltung.models.RechnungId]
		
		mappings {
			ch.openolitor.core.models {
				PersonId = 40000			
			}
			ch.openolitor.stammdaten.models {
				ProjektId = 1000
				DepotId = 10000
				TourId = 20000
				KundeId = 30000
				AbotypId = 50000
				ProduktId = 60000
				ProduzentId = 70000
				AboId = 100000
				VertriebId = 110000
			}
			ch.openolitor.buchhaltung.models {
				RechnungId = 200000
			}
		}
	}
	
	# Security configuration
	security {
		second-factor-auth {
			require = true
		}
		# max 20s delay
		max-request-delay = 20000
		
		cors {
			allow-origin = ["http://localhost:9000"]
		}
	}
	
  # JDBC settings
  db.default.driver="org.mariadb.jdbc.Driver"
  # Connection Pool settings
  db.default.poolInitialSize=2
  db.default.poolMaxSize=2
  db.default.poolConnectionTimeoutMillis=2000
  db.default.url="jdbc:mysql://localhost/scalikejdbc"
  db.default.maxPoolSize=2
  db.default.maxQueueSize=10000
  db.default.maxIdleMillis=2000
}

# Default akka configuration
akka {
	loglevel = "DEBUG",
	stdout-loglevel = "DEBUG",
	loggers = ["akka.event.slf4j.Slf4jLogger"]  	
  	logging-filter = "akka.event.slf4j.Slf4jLoggingFilter",
	persistence {
		journal.plugin = "akka-persistence-sql-async.journal"
		snapshot-store.plugin = "akka-persistence-sql-async.snapshot-store"
	},
	actor {
	  serializers {
	    event-serializer  = "ch.openolitor.core.eventsourcing.EventStoreSerializer"
	  },
	  serialization-bindings {
	    "ch.openolitor.core.domain.PersistentEvent" = event-serializer
	  }
    }
}	

# Default akka-persistence configuration
akka-persistence-sql-async {
  journal.class = "akka.persistence.journal.sqlasync.MySQLAsyncWriteJournal"
  snapshot-store.class = "akka.persistence.snapshot.sqlasync.MySQLSnapshotStore"

  max-pool-size = 2
  wait-queue-capacity = 10000

  metadata-table-name = "persistence_metadata"
  journal-table-name = "persistence_journal"
  snapshot-table-name = "persistence_snapshot"
}

# Configure own dispatcher for the reportsystem to control max used ressources
akka.actor.deployment {
  /oo-system/report-system {
    dispatcher = report-dispatcher
  }
}
report-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "thread-pool-executor"
  # Configuration for the thread pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 2
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 2.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 10
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}
